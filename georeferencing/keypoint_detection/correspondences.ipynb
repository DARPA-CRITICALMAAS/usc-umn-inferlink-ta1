{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXSxLsctywDm"
   },
   "source": [
    "# Deep ViT Features - Point Correspondences\n",
    "Given a pair of images, find $k$ semantic correspondences between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "XYCqRH11xqo7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Installations and mounting\n",
    "import sys\n",
    "sys.path.append('dino-vit-features')\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e8qCxV6x32E"
   },
   "source": [
    "## Change Runtime Type\n",
    "To get a GPU in Google Colab, go to the top menu: Runtime âž” Change runtime type and select GPU as Hardware accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "k14_KK3Cxqo9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#@title Configuration:\n",
    "#@markdown Choose image paths:\n",
    "\n",
    "image_path1 = '/scratch.global/chen7924/cropped_NGMDB_GF/10069_1.tif' #@param\n",
    "image_path2 = '/scratch.global/chen7924/topomaps_0101/topomaps_1130/CA_Piru_294178_1952_24000_geo.tif' #@param\n",
    "\n",
    "#@markdown Choose number of points to output:\n",
    "num_pairs = 10 #@param\n",
    "#@markdown Choose loading size:\n",
    "load_size = 224 #@param\n",
    "#@markdown Choose layer of descriptor:\n",
    "layer = 9 #@param\n",
    "#@markdown Choose facet of descriptor:\n",
    "facet = 'key' #@param\n",
    "#@markdown Choose if to use a binned descriptor:\n",
    "bin=True #@param\n",
    "#@markdown Choose fg / bg threshold:\n",
    "thresh=0.05 #@param\n",
    "#@markdown Choose model type:\n",
    "model_type='dino_vits8' #@param\n",
    "#@markdown Choose stride:\n",
    "stride=4 #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A6f_PAqxxqo-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yaoyi/chen7924/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 281, 224])\n",
      "torch.Size([1, 3, 273, 224])\n",
      "1.5810898952186108\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from correspondences import find_sims, draw_correspondences\n",
    "\n",
    "with torch.no_grad():\n",
    "    sims = find_sims(image_path1, image_path2, num_pairs, load_size, layer, facet, bin, thresh, model_type, stride)\n",
    "    print(sims)\n",
    "    # points1, points2, image1_pil, image2_pil = find_correspondences(image_path1, image_path2, num_pairs, load_size, layer,\n",
    "    #                                                                facet, bin, thresh, model_type, stride)\n",
    "# fig_1, ax1 = plt.subplots()\n",
    "# ax1.axis('off')\n",
    "# ax1.imshow(image1_pil)\n",
    "# fig_2, ax2 = plt.subplots()\n",
    "# ax2.axis('off')\n",
    "# ax2.imshow(image2_pil)\n",
    "\n",
    "\n",
    "# fig1, fig2 = draw_correspondences(points1, points2, image1_pil, image2_pil)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaoyi/chen7924/anaconda3/envs/gp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import argparse\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from correspondences import find_sims\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "def calc_geo_topo_correlation(gt_pair, geo_root, topo_root):# Paths to your images\n",
    "    geo_name, topos = gt_pair\n",
    "    geo_root = geo_root\n",
    "    topo_root = topo_root\n",
    "    geomap_path = os.path.join(geo_root, geo_name +'.tif')\n",
    "    print(geomap_path)\n",
    "    \n",
    "    \n",
    "    #For each geo-topo pair calculate, bbp sum similarity\n",
    "    sim_scores = []\n",
    "    for topo in topos:\n",
    "        topomap_path = os.path.join(topo_root, topo + '.tif')\n",
    "        print(topomap_path)\n",
    "        sim = find_sims(geomap_path, topomap_path)\n",
    "        sim_scores.append(sim)\n",
    "    \n",
    "    combined = list(zip(sim_scores, topos))\n",
    "    sorted_combined_list = sorted(combined_list, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Extract the sorted lists of integers and strings\n",
    "    sorted_integers, sorted_strings = zip(*sorted_combined_list)\n",
    "    \n",
    "    print(sorted_strings[0])\n",
    "    print(gt_true_dict[geo_name])\n",
    "    sys.exit()\n",
    "    return (geo_name, sorted_strings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_root = '/scratch.global/chen7924/cropped_NGMDB_GF'\n",
    "topo_root = '/scratch.global/chen7924/topomaps_0101/topomaps_1130'\n",
    "out_list = '/scratch.global/chen7924/semcorr_results/dino_vit_pairs.pkl'\n",
    "\n",
    "#load in dict with main pairs\n",
    "# with open('/home/yaoyi/chen7924/critical-maas/models/vit-topo/data/mn_geo-topo_pairs_90OR90.pickle', 'rb') as handle:\n",
    "#     geo_topo_pairs = pickle.load(handle)\n",
    "\n",
    "#Load in dict with incorrect rank 20 pairs\n",
    "with open('/home/yaoyi/chen7924/critical-maas/Data/semantic_correspondence/sem_corr_1-1_top20_f.pkl', 'rb') as handle:\n",
    "    rank20_dict_corr = pickle.load(handle)\n",
    "\n",
    "rank20_dict = {}\n",
    "for geo_name in rank20_dict_corr.keys():\n",
    "    geomap_path = os.path.join(geo_root, geo_name +'.tif')\n",
    "    if os.path.exists(geomap_path):\n",
    "        rank20_dict[geo_name] = rank20_dict_corr[geo_name]\n",
    "# del rank20_dict_corr\n",
    "# print(len(list(rank20_dict.keys())))\n",
    "# # Function to save strings to a pickle file\n",
    "# def save_strings(strings):\n",
    "#     with open(out_list, \"wb\") as file:\n",
    "#         pickle.dump(strings, file)   \n",
    "\n",
    "# results_list = []\n",
    "# strings_list = []\n",
    "# loop_counter = 0\n",
    "# for key, value in rank20_dict.items():\n",
    "#     pairs = calc_geo_topo_correlation((key, value), geo_root, topo_root)\n",
    "#     strings_list.append(pairs)\n",
    "#     loop_counter += 1\n",
    "#     if loop_counter % 100 == 0:\n",
    "#         print(f\"Accuracy after {loop_counter} threads: {sum(results_list)/len(results_list)}\")\n",
    "#         # Save the strings every 100 threads\n",
    "#         save_strings(sqtrings_list)\n",
    "\n",
    "# save_strings(strings_list)\n",
    "# print(f\"Accuracy after {loop_counter} threads: {sum(results_list)/len(results_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "correspondences.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gp",
   "language": "python",
   "name": "gp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
