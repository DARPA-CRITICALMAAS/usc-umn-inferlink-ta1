{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Polygon\n",
    "import shapely.wkt\n",
    "\n",
    "import csv\n",
    "\n",
    "import geopandas as gpd\n",
    "from osgeo import ogr, gdal, osr\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_source = 'Data/OR_Camas.tif' # raster tif\n",
    "path_to_legend_solution = 'Segmentation_Output/OR_Carlton/OR_Carlton_PolygonType.geojson' # geojson with properties => suffix: _PolygonType.geojson\n",
    "path_to_groundtruth_legend = 'Data/OR_Camas.json' # json listing all map keys => will be the same as the previous file\n",
    "\n",
    "dir_to_raster_polygon = 'LOAM/predict/fold_0/cma/predict/'\n",
    "dir_to_integrated_output = 'Vectorization_Output/OR_Camas'\n",
    "\n",
    "targeted_map_list = 'targeted_map.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chronology_age = ['Meghalayan', 'Northgrippian', 'Greenlandian', 'Late Pleistocene', 'Chibanian', 'Calabrian', 'Gelasian', \n",
    "                  'Piacenzian', 'Zanclean', 'Messinian', 'Tortonian', 'Serravallian', 'Langhian', 'Burdigalian', 'Aquitanian', \n",
    "                  'Chattian', 'Rupelian', 'Priabonian', 'Bartonian', 'Lutetian', 'Ypresian', 'Thanetian', 'Selandian', 'Danian', \n",
    "                  'Maastrichtian', 'Campanian', 'Santonian', 'Coniacian', 'Turonian', 'Cenomanian', 'Albian', 'Aptian', 'Barremian', 'Hauterivian', 'Valanginian', 'Berriasian', \n",
    "                  'Tithonian', 'Kimmeridgian', 'Oxfordian', 'Callovian', 'Bathonian', 'Bajocian', 'Aalenian', 'Toarcian', 'Pliensbachian', 'Sinemurian', 'Hettangian', \n",
    "                  'Rhaetian', 'Norian', 'Carnian', 'Ladinian', 'Anisian', 'Olenekian', 'Induan', \n",
    "                  'Changhsingian', 'Wuchiapingian', 'Capitanian', 'Wordian', 'Roadian', 'Kungurian', 'Artinskian', 'Sakmarian', 'Asselian', \n",
    "                  'Gzhelian', 'Kasimovian', 'Moscovian', 'Bashkirian', 'Serpukhovian', 'Vis√©an', 'Tournaisian', \n",
    "                  'Famennian', 'Frasnian', 'Givetian', 'Eifelian', 'Emsian', 'Pragian', 'Lochkovian', \n",
    "                  'Pridoli', 'Ludfordian', 'Gorstian', 'Homerian', 'Sheinwoodian', 'Telychian', 'Aeronian', 'Rhuddanian', \n",
    "                  'Hirnantian', 'Katian', 'Sandbian', 'Darriwilian', 'Dapingian', 'Floian', 'Tremadocian', \n",
    "                  'Stage 10', 'Jiangshanian', 'Paibian', 'Guzhangian', 'Drumian', 'Wuliuan', 'Stage 4', 'Stage 3', 'Stage 2', 'Fortunian', \n",
    "                  'Ediacaran', 'Cryogenian', 'Tonian', 'Stenian', 'Ectasian', 'Calymmian', 'Statherian', 'Orosirian', 'Rhyacian', 'Siderian', \n",
    "                  'Neoarchean', 'Mesoarchean', 'Paleoarchean', 'Eoarchean', 'Hadean'\n",
    "                  ]\n",
    "chronology_epoch = ['Holocene', 'Holocene', 'Holocene', 'Pleistocene', 'Pleistocene', 'Pleistocene', 'Pleistocene', \n",
    "                  'Pliocene', 'Pliocene', 'Miocene', 'Miocene', 'Miocene', 'Miocene', 'Miocene', 'Miocene', \n",
    "                  'Oligocene', 'Oligocene', 'Eocene', 'Eocene', 'Eocene', 'Eocene', 'Paleocene', 'Paleocene', 'Paleocene', \n",
    "                  'Late Cretaceous', 'Late Cretaceous', 'Late Cretaceous', 'Late Cretaceous', 'Late Cretaceous', 'Late Cretaceous', 'Early Cretaceous', 'Early Cretaceous', 'Early Cretaceous', 'Early Cretaceous', 'Early Cretaceous', 'Early Cretaceous', \n",
    "                  'Late Jurassic', 'Late Jurassic', 'Late Jurassic', 'Middle Jurassic', 'Middle Jurassic', 'Middle Jurassic', 'Middle Jurassic', 'Early Jurassic', 'Early Jurassic', 'Early Jurassic', 'Early Jurassic', \n",
    "                  'Late Triassic', 'Late Triassic', 'Late Triassic', 'Middle Triassic', 'Middle Triassic', 'Early Triassic', 'Early Triassic', \n",
    "                  'Lopingian', 'Lopingian', 'Guadalupian', 'Guadalupian', 'Guadalupian', 'Cisuralian', 'Cisuralian', 'Cisuralian', 'Cisuralian', \n",
    "                  'Pennsylvanian', 'Pennsylvanian', 'Pennsylvanian', 'Pennsylvanian', 'Mississippian', 'Mississippian', 'Mississippian', \n",
    "                  'Late Devonian', 'Late Devonian', 'Middle Devonian', 'Middle Devonian', 'Early Devonian', 'Early Devonian', 'Early Devonian', \n",
    "                  'Pridoli', 'Ludlow', 'Ludlow', 'Wenlock', 'Wenlock', 'Llandovery', 'Llandovery', 'Llandovery', \n",
    "                  'Late Ordovician', 'Late Ordovician', 'Late Ordovician', 'Middle Ordovician', 'Middle Ordovician', 'Early Ordovician', 'Early Ordovician', \n",
    "                  'Furongian', 'Furongian', 'Furongian', 'Miaolingian', 'Miaolingian', 'Miaolingian', 'Series 2', 'Series 2', 'Terreneuvian', 'Terreneuvian', \n",
    "                  'Ediacaran', 'Cryogenian', 'Tonian', 'Stenian', 'Ectasian', 'Calymmian', 'Statherian', 'Orosirian', 'Rhyacian', 'Siderian', \n",
    "                  'Neoarchean', 'Mesoarchean', 'Paleoarchean', 'Eoarchean', 'Hadean',\n",
    "                  ]\n",
    "chronology_period = ['Quaternary', 'Quaternary', 'Quaternary', 'Quaternary', 'Quaternary', 'Quaternary', 'Quaternary', \n",
    "                  'Neogene', 'Neogene', 'Neogene', 'Neogene', 'Neogene', 'Neogene', 'Neogene', 'Neogene', \n",
    "                  'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', 'Paleogene', \n",
    "                  'Cretaceous', 'Cretaceous', 'LCretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', 'Cretaceous', \n",
    "                  'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', 'Jurassic', \n",
    "                  'Triassic', 'Triassic', 'Triassic', 'Triassic', 'Triassic', 'Triassic', 'Triassic', \n",
    "                  'Permian', 'Permian', 'Permian', 'Permian', 'Permian', 'Permian', 'Permian', 'Permian', 'Permian', \n",
    "                  'Carboniferous', 'Carboniferous', 'Carboniferous', 'Carboniferous', 'Carboniferous', 'Carboniferous', 'Carboniferous', \n",
    "                  'Devonian', 'Devonian', 'Devonian', 'Devonian', 'Devonian', 'Devonian', 'Devonian', \n",
    "                  'Silurian', 'Silurian', 'Silurian', 'Silurian', 'Silurian', 'Silurian', 'Silurian', 'Silurian', \n",
    "                  'Ordovician', 'Ordovician', 'Ordovician', 'Ordovician', 'Ordovician', 'Ordovician', 'Ordovician', \n",
    "                  'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', 'Cambrian', \n",
    "                  'Ediacaran', 'Cryogenian', 'Tonian', 'Stenian', 'Ectasian', 'Calymmian', 'Statherian', 'Orosirian', 'Rhyacian', 'Siderian', \n",
    "                  'Neoarchean', 'Mesoarchean', 'Paleoarchean', 'Eoarchean', 'Hadean',\n",
    "                  ]\n",
    "\n",
    "chronology_age = np.array(chronology_age)\n",
    "chronology_epoch = np.array(chronology_epoch)\n",
    "chronology_period = np.array(chronology_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Put the targeted map name here']]\n"
     ]
    }
   ],
   "source": [
    "file_target_map = open(targeted_map_list, 'r')\n",
    "data_target_map = list(csv.reader(file_target_map, delimiter=','))\n",
    "file_target_map.close()\n",
    "print(data_target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['OR_Camas.tif']]\n"
     ]
    }
   ],
   "source": [
    "data_target_map = [['OR_Camas.tif']]\n",
    "print(data_target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(dir_to_integrated_output):\n",
    "    os.makedirs(dir_to_integrated_output)\n",
    "\n",
    "\n",
    "\n",
    "map_name = data_target_map[0][0].replace('.tif', '')\n",
    "if not os.path.exists(os.path.join(dir_to_integrated_output, map_name)):\n",
    "    os.makedirs(os.path.join(dir_to_integrated_output, map_name))\n",
    "\n",
    "polygon_type_db = gpd.read_file(path_to_legend_solution, driver='GeoJSON')\n",
    "\n",
    "\n",
    "polygon_feature_counter = 0    \n",
    "for fname in os.listdir(dir_to_raster_polygon):    # change directory as needed\n",
    "    if os.path.isfile(os.path.join(dir_to_raster_polygon, fname)):\n",
    "        #print(os.path.join(dir_to_raster_polygon, fname), map_name.replace('.tif', '_'))\n",
    "        if '_predict.png' in fname and map_name.replace('.tif', '_') in fname:\n",
    "            this_abbr = fname.split('_')[-3]\n",
    "            print(this_abbr)\n",
    "\n",
    "            info_for_this_poly = polygon_type_db[(polygon_type_db['abbreviation'] == this_abbr)]\n",
    "            #print(info_for_this_poly)\n",
    "            print(info_for_this_poly.shape[0])\n",
    "\n",
    "\n",
    "            b_epoch = chronology_period.shape[0]\n",
    "            t_epoch = -1\n",
    "            b_interval = ''\n",
    "            t_interval = ''\n",
    "            b_age = ''\n",
    "            t_age = ''\n",
    "\n",
    "            if info_for_this_poly.shape[0] > 0:\n",
    "                if info_for_this_poly['name'].values.shape[0] > 0 and info_for_this_poly['description'].values.shape[0] > 0:\n",
    "                    testing_string = str(info_for_this_poly['name'].values[0]) + ': ' + str(info_for_this_poly['description'].values[0])\n",
    "                elif info_for_this_poly['name'].values.shape[0] > 0:\n",
    "                    testing_string = str(info_for_this_poly['name'].values[0])\n",
    "                else:\n",
    "                    testing_string = ''\n",
    "                \n",
    "                epoch_check = np.flatnonzero(np.core.defchararray.find(testing_string, chronology_period)!=-1)\n",
    "                if epoch_check.shape[0] > 0:\n",
    "                    b_epoch = max(epoch_check)\n",
    "                    t_epoch = min(epoch_check)\n",
    "                \n",
    "                epoch_check = np.flatnonzero(np.core.defchararray.find(testing_string, chronology_epoch)!=-1)\n",
    "                if epoch_check.shape[0] > 0:\n",
    "                    b_epoch = min(b_epoch ,max(epoch_check))\n",
    "                    t_epoch = max(t_epoch, min(epoch_check))\n",
    "\n",
    "                epoch_check = np.flatnonzero(np.core.defchararray.find(testing_string, chronology_age)!=-1)\n",
    "                if epoch_check.shape[0] > 0:\n",
    "                    b_epoch = min(b_epoch ,max(epoch_check))\n",
    "                    t_epoch = max(t_epoch, min(epoch_check))\n",
    "\n",
    "                #print(testing_string,b_epoch, t_epoch, b_interval, t_interval, b_age, t_age)\n",
    "                if b_epoch != chronology_period.shape[0] and t_epoch != -1:\n",
    "                    b_interval = chronology_epoch[b_epoch]\n",
    "                    t_interval = chronology_epoch[t_epoch]\n",
    "                    b_age = chronology_age[b_epoch]\n",
    "                    t_age = chronology_age[t_epoch]\n",
    "            \n",
    "            in_path = os.path.join(dir_to_raster_polygon, fname)\n",
    "            base_image = cv2.imread(in_path)\n",
    "            base_image = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            out_path = os.path.join(dir_to_integrated_output, map_name, fname.replace('_predict.png', '.geojson'))\n",
    "\n",
    "            src_ds = gdal.Open(in_path)\n",
    "            srcband = src_ds.GetRasterBand(1)\n",
    "            dst_layername = 'polygon'\n",
    "            drv = ogr.GetDriverByName('geojson')\n",
    "            dst_ds = drv.CreateDataSource(out_path)\n",
    "\n",
    "            sp_ref = osr.SpatialReference()\n",
    "            sp_ref.SetFromUserInput('EPSG:3857')\n",
    "\n",
    "            dst_layer = dst_ds.CreateLayer(dst_layername, srs = sp_ref )\n",
    "            gdal.Polygonize( srcband, None, dst_layer, 0, [], callback=None )\n",
    "\n",
    "            del src_ds\n",
    "            del dst_ds\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            mirrored_polygon = gpd.GeoDataFrame(columns=['id', 'name', 'geometry', \n",
    "                                                            'PolygonType', #: {'id', 'name', 'color', 'pattern', 'abbreviation', 'description', 'category'},  \n",
    "                                                            'GeologicUnit'#: {'name', 'description', 'comments', 'age_text', 't_interval', 'b_interval', 't_age', 'b_age', 'lithology'}\n",
    "                                                            ], crs=polygon_type_db.crs)\n",
    "            polygon_extraction = gpd.read_file(os.path.join(dir_to_integrated_output, map_name, fname.replace('_predict.png', '.geojson')), driver='GeoJSON')\n",
    "            \n",
    "\n",
    "            for index, poi in polygon_extraction.iterrows():\n",
    "                if index == polygon_extraction.shape[0]-1:\n",
    "                    break\n",
    "                this_mirrored_polygon = shapely.wkt.loads(str(poi['geometry']).replace(', ', 'p').replace(' ', ' -').replace('p', ', ').replace('POLYGON -', 'POLYGON '))\n",
    "\n",
    "                if info_for_this_poly.shape[0] != 1:\n",
    "                    updated_record = gpd.GeoDataFrame([{'id':polygon_feature_counter, 'name':'PolygonFeature', 'geometry':this_mirrored_polygon, \n",
    "                                                            'PolygonType': {'id':None, 'name':None, 'color':None, 'pattern':None, 'abbreviation':None, 'description':None, 'category':None},  \n",
    "                                                            'GeologicUnit': {'name':None, 'description':None, 'comments':None, 'age_text':None, 't_interval':None, 'b_interval':None, 't_age':None, 'b_age':None, 'lithology':None}}])\n",
    "                else:\n",
    "                    if b_epoch != chronology_period.shape[0]:\n",
    "                        updated_record = gpd.GeoDataFrame([{'id':polygon_feature_counter, 'name':'PolygonFeature', 'geometry':this_mirrored_polygon, \n",
    "                                                            'PolygonType': {'id':int(info_for_this_poly['id'].values[0]), 'name':str(info_for_this_poly['name'].values[0]), 'color':str(info_for_this_poly['color'].values[0]), 'pattern':str(info_for_this_poly['pattern'].values[0]), 'abbreviation':str(info_for_this_poly['abbreviation'].values[0]), 'description':str(info_for_this_poly['description'].values[0]), 'category':str(info_for_this_poly['category'].values[0])}, \n",
    "                                                            'GeologicUnit': {'name':None, 'description':None, 'comments':None, 'age_text':str(b_age)+' - '+str(t_age), 't_interval':str(t_interval), 'b_interval':str(b_interval), 't_age':str(t_age), 'b_age':str(b_age), 'lithology':None}}])\n",
    "                    else:\n",
    "                        updated_record = gpd.GeoDataFrame([{'id':polygon_feature_counter, 'name':'PolygonFeature', 'geometry':this_mirrored_polygon, \n",
    "                                                            'PolygonType': {'id':int(info_for_this_poly['id'].values[0]), 'name':str(info_for_this_poly['name'].values[0]), 'color':str(info_for_this_poly['color'].values[0]), 'pattern':str(info_for_this_poly['pattern'].values[0]), 'abbreviation':str(info_for_this_poly['abbreviation'].values[0]), 'description':str(info_for_this_poly['description'].values[0]), 'category':str(info_for_this_poly['category'].values[0])}, \n",
    "                                                            'GeologicUnit': {'name':None, 'description':None, 'comments':None, 'age_text':None, 't_interval':None, 'b_interval':None, 't_age':None, 'b_age':None, 'lithology':None}}])\n",
    "\n",
    "                mirrored_polygon = gpd.GeoDataFrame(pd.concat( [mirrored_polygon, updated_record], ignore_index=True), crs=polygon_type_db.crs)\n",
    "\n",
    "                polygon_feature_counter += 1\n",
    "            \n",
    "            #print(mirrored_polygon)\n",
    "\n",
    "            mirrored_polygon = mirrored_polygon.set_crs('epsg:3857', allow_override=True)\n",
    "            mirrored_polygon.to_file(os.path.join(dir_to_integrated_output, fname.replace('_predict.png', '_PolygonFeature.geojson')), driver='GeoJSON')\n",
    "\n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
